{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch tiles from Landsat\n",
    "\n",
    "The code in this notebook shows the process of fetching landsat tiles from the USGS server, changing the format of the data, checking for actual data compatibility, and pre-processing into (file,window) pairs.\n",
    "\n",
    "For the first task, fetching from USGS, you need to have a USGS account, and have the username and password in the USGS_USER and USGS_PASSWORD environment variables, respectively.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:32:07.069057Z",
     "start_time": "2019-09-17T22:32:05.745059Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "from landsat5fetch import *\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "storage_directory = Path(os.getenv('LANDSAT_DIR'))  # set storage_directory however you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:32:14.359063Z",
     "start_time": "2019-09-17T22:32:14.355062Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare session with USGS Server\n",
    "s = get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T23:19:47.072371Z",
     "start_time": "2019-09-17T23:19:47.052380Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Create list of candidate landsat tiles \n",
    "# The file landsat5list.py contains a list of potential tiles that overlap the Corine map, and occur in the same time\n",
    "# frame as the Corine report.\n",
    "# (Obviously you could substitute any other tile list you wanted.)\n",
    "\n",
    "import landsat5list\n",
    "lst = np.array(landsat5list.potential_tiles)\n",
    "wehave = list(storage_directory.glob('*.tif'))\n",
    "candidates = list(set(lst) - set( [x.stem for x in wehave ]))\n",
    "print( len(lst), len(wehave), len(candidates) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:32:28.493065Z",
     "start_time": "2019-09-17T22:32:28.444069Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select some tiles at random\n",
    "# USGS seems to have a limit of 20 that it will allow you to request at a time\n",
    "np.random.shuffle(candidates)\n",
    "tofetch = list(candidates[:20])\n",
    "tofetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T07:20:26.735529Z",
     "start_time": "2018-12-02T07:20:25.370614Z"
    }
   },
   "outputs": [],
   "source": [
    "submit_order(list(tofetch))\n",
    "# Note: if you get a 400 (BAD REQUEST) error, it is probably because you've exceeded some resource limit, \n",
    "# not actually a bad request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T09:53:01.854610Z",
     "start_time": "2018-12-02T09:53:01.081833Z"
    }
   },
   "outputs": [],
   "source": [
    "# Confirm the order\n",
    "get_open_orders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T09:57:28.277362Z",
     "start_time": "2018-12-02T09:53:58.938599Z"
    }
   },
   "outputs": [],
   "source": [
    "# After you have received the 'download ready' email from USGS,\n",
    "# you can download the results.\n",
    "downloaded = download_available_results(storage_directory)\n",
    "len(downloaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the Files\n",
    "Now we need to process the data from the form we get it from landsat (a gzipped tar file) into the form we  will use (a tif file). Ideally we'd do that processing right here in the notebook, but I haven't figured out how to set a conda environment for subshell in jupyter.  So for now, you have to open a terminal, activate the right conda environment, then run the shell script ls5munge.sh manually.\n",
    "````\n",
    "# Usage:  ./ls5munge.sh <landsat_diretory>/*.tar.gz\n",
    "````\n",
    "Note: it will automatically skip files that have already been processed, so you don't have to worry about telling it exactly which ones are the new ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Tiles\n",
    "In this section, we analyze the downloaded results for compatibility with the Corine data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:33:56.925397Z",
     "start_time": "2019-09-17T22:33:54.716521Z"
    }
   },
   "outputs": [],
   "source": [
    "# append the parent directory to the python path so that we can import tools for analysis\n",
    "import sys\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from multispectral import corine\n",
    "from multispectral import coords\n",
    "from multispectral import tools\n",
    "import rasterio\n",
    "tools.set_figure_width(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:34:40.505705Z",
     "start_time": "2019-09-17T22:34:40.496722Z"
    }
   },
   "outputs": [],
   "source": [
    "#tocheck = list(storage_directory.glob('*.tif'))  # to look at all files\n",
    "tocheck = [ storage_directory / (x + \".tif\") for x in downloaded ]\n",
    "len(tocheck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all the tiles in landsat5list.py will actually be useful--they won't all intersect the Corine data.\n",
    "There are two reasons for this: (1) The tiles in landsat5list.py were generated from an _approximation_ of the \n",
    "Corine outline, and (2) both the tiles and the Corine data don't completely fill their rectangular extents, so even when the rectangles overlap, the data may not.\n",
    "\n",
    "The loop below will find tiles that don't have a proper overlap.\n",
    "For any file identified here, you should remove it from storage_directory, *and* comment it out of landsat5list.py to\n",
    "prevent it from being downloaded again. In fact, you can comment out the entire pathrow combination (see the file for examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:34:57.192685Z",
     "start_time": "2019-09-17T22:34:54.237635Z"
    }
   },
   "outputs": [],
   "source": [
    "def smudge(pw1, pw2):\n",
    "    \"\"\"Due to rounding errors, it is possible that the same geo window results in pixel windows of two different sizes\n",
    "    for different data files.  Smudge adjusts a matching pair of pixel windows so that they are definitely the same\n",
    "    size.   Currently nothing clever here about geo registration; just making the height/width match.\"\"\"\n",
    "    common_height = min(pw1.height,pw2.height)\n",
    "    common_width = min(pw1.width,pw2.width)\n",
    "    if pw1.width != common_width or pw1.height != common_height:\n",
    "        pw1 = rasterio.windows.Window(pw1.col_off,pw1.row_off,common_width,common_height)\n",
    "    if pw2.width != common_width or pw2.height != common_height:\n",
    "        pw2 = rasterio.windows.Window(pw2.col_off,pw2.row_off,common_width,common_height)\n",
    "    return (pw1,pw2)\n",
    "\n",
    "\n",
    "failed = []\n",
    "successful = []\n",
    "for file in tocheck:\n",
    "    fp = rasterio.open(file)\n",
    "    cp = corine.fetch_corine(fp.crs)\n",
    "    geo_common = coords.geo_window_intersect(fp.bounds,cp.bounds)\n",
    "    if geo_common is None:\n",
    "        # This case shouldn't happen, and probably should be investigated.\n",
    "        failed.append(file)\n",
    "        print(\"{} does not intersect {}\".format(file.name, cp.name))\n",
    "        continue\n",
    "    \n",
    "    fp_window = coords.geo_to_pixel(fp,geo_common)\n",
    "    cp_window = coords.geo_to_pixel(cp,geo_common)\n",
    "    (fp_window,cp_window) = smudge(fp_window,cp_window)\n",
    "    \n",
    "    # check to see if the non-nodata bits overlap\n",
    "    fp_patch = fp.read(7, window=fp_window)\n",
    "    if not fp_patch.any():\n",
    "        failed.append(file)\n",
    "        print(\"{} is empty in intersection\".format(file.name))\n",
    "        continue\n",
    "        \n",
    "    cp_patch = cp.read(1, window=cp_window)\n",
    "    if not cp_patch.any():\n",
    "        failed.append(file)\n",
    "        print(\"{} intersects empty part of corine\".format(file.name))\n",
    "        continue\n",
    "    \n",
    "    common_data = np.logical_and(fp_patch,cp_patch)\n",
    "    if not common_data.any():\n",
    "        failed.append(file)\n",
    "        print(\"{} and {} have no common data\".format(file.name, cp.name))\n",
    "        continue\n",
    "    \n",
    "    successful.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-17T22:35:04.706775Z",
     "start_time": "2019-09-17T22:35:04.699783Z"
    }
   },
   "outputs": [],
   "source": [
    "len(failed), len(successful)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the location of tiles superimposed on the corine maps.  You should generally expect failed tiles to be visibly outside or on the edge \n",
    "of the corine data.  If they are not, it may mean the landsat data is corrupted, or a bug, or...\n",
    "\n",
    "(Note that some of the Corine outlines may be a bit hard to recognize because the corine data extends out into the ocean for some ways.  But rest assured each segment is some slice of Europe.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in failed:  # 'tocheck', 'failed' or 'successful'\n",
    "    fp = rasterio.open(file)\n",
    "    cp = corine.fetch_corine(fp.crs)\n",
    "    tools.show_bands(cp,1,showrect=coords.geo_to_pixel(cp,fp.bounds).flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precompute Windows\n",
    "The data is now available for use.  However for efficiency we usually preprocess it to create a master list of (tile, window) tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you didn't do this above, do it now\n",
    "# append the parent directory to the python path so that we can import tools for analysis\n",
    "import sys\n",
    "sys.path.append(str(Path(\"..\").resolve()))\n",
    "\n",
    "from multispectral import corine\n",
    "from multispectral import coords\n",
    "from multispectral import tools\n",
    "import rasterio\n",
    "tools.set_figure_width(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The file where we will store the master list of all windows.\n",
    "window_list_file = storage_directory / \"all_windows.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_process = list(storage_directory.glob('*.tif'))  # If you want to recompute all windows from scratch:\n",
    "to_process = successful  # to add new files to the list\n",
    "to_process[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presumably we are only processing tiles that have valid overlap with the Corine data.  But even though the tile may have overlap, individual windows may not.  In fact, many windows around the edge of the tile will have only NODATA values, and so not be useful to us at all.  Prefiltering filters out the NODATA windows and also does the same kind of overlap analysis we did above with the Corine data.  The windows that are left are known to have good overlapping data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows_list = list( windows.prefilter(to_process, corine.corine_filter)) \n",
    "len(windows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As an extra check, you can see how many windows of each type were produced by each tile.\n",
    "corine._tile_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the windows for re-use.  I'm keeping all windows together in one master file that is used as input to the learners.  Store them however you like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the new list to the master list\n",
    "windows.to_file(windows_list, window_list_file, append=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or, to read from the file\n",
    "# windows_list = windows.from_file(windows_list_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is nice to see what you actually have. This code will show the windows superimposed on the Corine map segments.  I find it very gratifying to see the outlines of the Corine data neatly mapped to windows. :-)\n",
    "You can do this even with many thousands of windows, but not surprisingly it can get kind of slow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First sort the windows by corine segment\n",
    "cdats = {}\n",
    "for (ld,w) in windows_list:\n",
    "    cdat = corine.fetch_corine(ld.crs)\n",
    "    if cdat not in cdats:\n",
    "        cdats[cdat] = []\n",
    "    cdats[cdat].append((ld,w))\n",
    "\n",
    "# How many windows on each segment?\n",
    "for cdat in cdats:\n",
    "    print(\"{}: {}\".format(cdat.name, len(cdats[cdat])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show them all...\n",
    "for cdat, wl in cdats.items():\n",
    "    rs = [coords.geo_to_pixel(cdat, coords.pixel_to_geo(x,y)).flatten() for (x,y) in wl ]\n",
    "    tools.show_band(cdat,1,showrect=rs)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python [conda env:fastai]",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}